{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mercedes F1 Infringement Documents - Preprocessing\n",
        "\n",
        "This notebook performs preprocessing on Mercedes infringement documents to prepare them for text mining and summarization.\n",
        "\n",
        "## Preprocessing Steps:\n",
        "1. **Article Removal**: Remove common articles like \"the\", \"a\", \"an\"\n",
        "2. **Additional preprocessing steps** (to be added)\n",
        "\n",
        "## Objective:\n",
        "- Clean and normalize Mercedes infringement text data\n",
        "- Prepare consolidated datasets for each year\n",
        "- Remove unnecessary words while preserving important information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "Base path: Documents\n",
            "Output directory: pre_proc_op\n",
            "Year folders created: ['2020', '2021', '2022', '2023', '2024']\n",
            "\n",
            "Existing Mercedes TXT files:\n",
            "  2020_inf_profile: 11 TXT files\n",
            "  2021_inf_profile: 16 TXT files\n",
            "  2022_inf_profile: 15 TXT files\n",
            "  2023_inf_profile: 23 TXT files\n",
            "  2024_inf_profile: 17 TXT files\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "base_path = Path(\"Documents\")\n",
        "years = [\"2020_inf_profile\", \"2021_inf_profile\", \n",
        "         \"2022_inf_profile\", \"2023_inf_profile\", \"2024_inf_profile\"]\n",
        "\n",
        "# Create output directory structure\n",
        "output_dir = Path(\"pre_proc_op\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Create year subfolders\n",
        "year_folders = {}\n",
        "for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "    year_folder = output_dir / year\n",
        "    year_folder.mkdir(exist_ok=True)\n",
        "    year_folders[year] = year_folder\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"Base path: {base_path}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"Year folders created: {list(year_folders.keys())}\")\n",
        "\n",
        "# Check existing TXT files\n",
        "print(f\"\\nExisting Mercedes TXT files:\")\n",
        "for year_folder in years:\n",
        "    year_path = base_path / year_folder\n",
        "    if year_path.exists():\n",
        "        txt_count = len(list(year_path.glob(\"*.txt\")))\n",
        "        print(f\"  {year_folder}: {txt_count} TXT files\")\n",
        "    else:\n",
        "        print(f\"  {year_folder}: Folder not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing test:\n",
            "Original: The Mercedes team was fined for the violation of the track limits during the race.\n",
            "After article removal: Mercedes team was fined for violation of track limits during race.\n",
            "After full preprocessing: Mercedes team was fined for violation of track limits during race.\n"
          ]
        }
      ],
      "source": [
        "# Define preprocessing functions\n",
        "\n",
        "def remove_articles(text):\n",
        "    \"\"\"\n",
        "    Remove common articles (the, a, an) from text\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    \n",
        "    # Define articles to remove\n",
        "    articles = ['the', 'a', 'an']\n",
        "    \n",
        "    # Split text into words\n",
        "    words = text.split()\n",
        "    \n",
        "    # Filter out articles (case-insensitive)\n",
        "    filtered_words = []\n",
        "    for word in words:\n",
        "        # Remove punctuation and convert to lowercase for comparison\n",
        "        clean_word = re.sub(r'[^\\w]', '', word.lower())\n",
        "        if clean_word not in articles:\n",
        "            filtered_words.append(word)\n",
        "    \n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "def basic_clean(text):\n",
        "    \"\"\"\n",
        "    Basic text cleaning - normalize whitespace\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    \n",
        "    # Remove excessive whitespace and normalize\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    \n",
        "    # Apply preprocessing steps\n",
        "    text = basic_clean(text)\n",
        "    text = remove_articles(text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Test the preprocessing functions\n",
        "test_text = \"The Mercedes team was fined for the violation of the track limits during the race.\"\n",
        "print(\"Preprocessing test:\")\n",
        "print(f\"Original: {test_text}\")\n",
        "print(f\"After article removal: {remove_articles(test_text)}\")\n",
        "print(f\"After full preprocessing: {preprocess_text(test_text)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PREPROCESSING MERCEDES DOCUMENTS\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "PROCESSING 2020_INF_PROFILE\n",
            "==================================================\n",
            "\n",
            "Processing 11 files in 2020...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2020: 100%|██████████| 11/11 [00:00<00:00, 124.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Processed 11 documents in 2020_inf_profile\n",
            "\n",
            "==================================================\n",
            "PROCESSING 2021_INF_PROFILE\n",
            "==================================================\n",
            "\n",
            "Processing 16 files in 2021...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2021: 100%|██████████| 16/16 [00:00<00:00, 184.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Processed 16 documents in 2021_inf_profile\n",
            "\n",
            "==================================================\n",
            "PROCESSING 2022_INF_PROFILE\n",
            "==================================================\n",
            "\n",
            "Processing 15 files in 2022...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2022: 100%|██████████| 15/15 [00:00<00:00, 347.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Processed 15 documents in 2022_inf_profile\n",
            "\n",
            "==================================================\n",
            "PROCESSING 2023_INF_PROFILE\n",
            "==================================================\n",
            "\n",
            "Processing 23 files in 2023...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2023: 100%|██████████| 23/23 [00:00<00:00, 347.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Processed 23 documents in 2023_inf_profile\n",
            "\n",
            "==================================================\n",
            "PROCESSING 2024_INF_PROFILE\n",
            "==================================================\n",
            "\n",
            "Processing 17 files in 2024...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2024: 100%|██████████| 17/17 [00:00<00:00, 288.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Processed 17 documents in 2024_inf_profile\n",
            "\n",
            "Total documents processed: 82\n"
          ]
        }
      ],
      "source": [
        "# Process individual documents and create preprocessed versions\n",
        "\n",
        "def process_year_documents(year_folder):\n",
        "    \"\"\"\n",
        "    Process all Mercedes documents in a year folder\n",
        "    \"\"\"\n",
        "    year_path = base_path / year_folder\n",
        "    year_display = year_folder.replace('_inf_profile', '')\n",
        "    \n",
        "    if not year_path.exists():\n",
        "        print(f\"Folder {year_path} does not exist\")\n",
        "        return []\n",
        "    \n",
        "    # Get all TXT files\n",
        "    txt_files = list(year_path.glob(\"*.txt\"))\n",
        "    print(f\"\\nProcessing {len(txt_files)} files in {year_display}...\")\n",
        "    \n",
        "    processed_docs = []\n",
        "    \n",
        "    for txt_file in tqdm(txt_files, desc=f\"Processing {year_display}\"):\n",
        "        try:\n",
        "            # Read original text\n",
        "            with open(txt_file, 'r', encoding='utf-8') as f:\n",
        "                original_text = f.read()\n",
        "            \n",
        "            # Preprocess the text\n",
        "            preprocessed_text = preprocess_text(original_text)\n",
        "            \n",
        "            # Create output filename with \"no_articles_\" prefix\n",
        "            output_filename = f\"no_articles_{txt_file.name}\"\n",
        "            output_path = year_folders[year_display] / output_filename\n",
        "            \n",
        "            # Save preprocessed text\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(preprocessed_text)\n",
        "            \n",
        "            processed_docs.append({\n",
        "                'year': year_display,\n",
        "                'original_file': txt_file.name,\n",
        "                'preprocessed_file': output_filename,\n",
        "                'original_length': len(original_text),\n",
        "                'preprocessed_length': len(preprocessed_text),\n",
        "                'reduction_percent': ((len(original_text) - len(preprocessed_text)) / len(original_text)) * 100 if len(original_text) > 0 else 0\n",
        "            })\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {txt_file.name}: {e}\")\n",
        "    \n",
        "    return processed_docs\n",
        "\n",
        "# Process all years\n",
        "print(\"=\"*60)\n",
        "print(\"PREPROCESSING MERCEDES DOCUMENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_processed_docs = []\n",
        "\n",
        "for year_folder in years:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"PROCESSING {year_folder.upper()}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    processed_docs = process_year_documents(year_folder)\n",
        "    if processed_docs:\n",
        "        all_processed_docs.extend(processed_docs)\n",
        "        print(f\"\\n✓ Processed {len(processed_docs)} documents in {year_folder}\")\n",
        "    else:\n",
        "        print(f\"\\n✗ No documents processed in {year_folder}\")\n",
        "\n",
        "print(f\"\\nTotal documents processed: {len(all_processed_docs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "PREPROCESSING SUMMARY\n",
            "============================================================\n",
            "Total documents processed: 82\n",
            "Total original characters: 137,437\n",
            "Total preprocessed characters: 127,399\n",
            "Overall reduction: 7.1%\n",
            "\n",
            "Preprocessing results by year:\n",
            "--------------------------------------------------\n",
            "      Documents  Original_Chars  Preprocessed_Chars  Avg_Reduction_%\n",
            "year                                                                \n",
            "2020         11           17830               16581              7.1\n",
            "2021         16           28277               26159              6.9\n",
            "2022         15           22467               20923              6.8\n",
            "2023         23           37206               34475              7.1\n",
            "2024         17           31657               29261              7.5\n",
            "\n",
            "Sample preprocessing results:\n",
            "--------------------------------------------------\n",
            "Sample file: 2020 Austrian Grand Prix - Decision - Car 44 - alleged failure to slow for yellow flags.txt\n",
            "Preprocessed file: no_articles_2020 Austrian Grand Prix - Decision - Car 44 - alleged failure to slow for yellow flags.txt\n",
            "Original length: 1438 chars\n",
            "Preprocessed length: 1350 chars\n",
            "Reduction: 6.1%\n",
            "\n",
            "Summary saved to: pre_proc_op\\preprocessing_summary.csv\n",
            "\n",
            "Output directory structure:\n",
            "------------------------------\n",
            "pre_proc_op/\n",
            "├── 2020/ (11 files)\n",
            "│   ├── no_articles_2020 Austrian Grand Prix - Decision - Car 44 - alleged failure to slow for yellow flags.txt\n",
            "│   ├── no_articles_2020 Austrian Grand Prix - Decision - review of decision (document 33).txt\n",
            "│   ├── no_articles_2020 Austrian Grand Prix - Offence - Car 44 - Failure to slow for yellow flags (post review).txt\n",
            "│   └── ... and 8 more files\n",
            "├── 2021/ (16 files)\n",
            "│   ├── no_articles_2021 Austrian Grand Prix - Decision - Car 77 - Alleged driving unnecessarily slowly .txt\n",
            "│   ├── no_articles_2021 Brazilian Grand Prix - Offence - Car 44 - DRS.txt\n",
            "│   ├── no_articles_2021 Brazilian Grand Prix - Offence - Car 44 - PU element.txt\n",
            "│   └── ... and 13 more files\n",
            "├── 2022/ (15 files)\n",
            "│   ├── no_articles_2022 Abu Dhabi Grand Prix - Decision - Car 44 - Red Flag_0.txt\n",
            "│   ├── no_articles_2022 Abu Dhabi Grand Prix - Offence - Car 44 - Pit lane speeding.txt\n",
            "│   ├── no_articles_2022 Abu Dhabi Grand Prix - Offence - Car 63 - Unsafe release.txt\n",
            "│   └── ... and 12 more files\n",
            "├── 2023/ (23 files)\n",
            "│   ├── no_articles_2023 Abu Dhabi Grand Prix - Infringement - Mercedes - Team Principal (Updated).txt\n",
            "│   ├── no_articles_2023 Australian Grand Prix - Decision - Mercedes - Inaccurate Self Scrutineering Form.txt\n",
            "│   ├── no_articles_2023 Austrian Grand Prix - Infringement - Car 44 - Leaving the track multiple times.txt\n",
            "│   └── ... and 20 more files\n",
            "├── 2024/ (17 files)\n",
            "│   ├── no_articles_2024 Austrian Grand Prix - Infringement - Car 44 - Crossing the line at Pit Entry.txt\n",
            "│   ├── no_articles_2024 Austrian Grand Prix - Infringement - Car 44 - Unsafe release.txt\n",
            "│   ├── no_articles_2024 Azerbaijan Grand Prix - Infringement - Car 44 - Changes made during Parc Ferme.txt\n",
            "│   └── ... and 14 more files\n"
          ]
        }
      ],
      "source": [
        "# Summary and analysis of preprocessing results\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PREPROCESSING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if all_processed_docs:\n",
        "    # Create DataFrame for analysis\n",
        "    df_processed = pd.DataFrame(all_processed_docs)\n",
        "    \n",
        "    print(f\"Total documents processed: {len(all_processed_docs)}\")\n",
        "    print(f\"Total original characters: {df_processed['original_length'].sum():,}\")\n",
        "    print(f\"Total preprocessed characters: {df_processed['preprocessed_length'].sum():,}\")\n",
        "    print(f\"Overall reduction: {df_processed['reduction_percent'].mean():.1f}%\")\n",
        "    \n",
        "    print(f\"\\nPreprocessing results by year:\")\n",
        "    print(\"-\" * 50)\n",
        "    year_summary = df_processed.groupby('year').agg({\n",
        "        'original_file': 'count',\n",
        "        'original_length': 'sum',\n",
        "        'preprocessed_length': 'sum',\n",
        "        'reduction_percent': 'mean'\n",
        "    }).round(1)\n",
        "    \n",
        "    year_summary.columns = ['Documents', 'Original_Chars', 'Preprocessed_Chars', 'Avg_Reduction_%']\n",
        "    print(year_summary)\n",
        "    \n",
        "    # Show sample of preprocessing\n",
        "    print(f\"\\nSample preprocessing results:\")\n",
        "    print(\"-\" * 50)\n",
        "    sample_doc = all_processed_docs[0]\n",
        "    print(f\"Sample file: {sample_doc['original_file']}\")\n",
        "    print(f\"Preprocessed file: {sample_doc['preprocessed_file']}\")\n",
        "    print(f\"Original length: {sample_doc['original_length']} chars\")\n",
        "    print(f\"Preprocessed length: {sample_doc['preprocessed_length']} chars\")\n",
        "    print(f\"Reduction: {sample_doc['reduction_percent']:.1f}%\")\n",
        "    \n",
        "    # Save summary\n",
        "    df_processed.to_csv(output_dir / 'preprocessing_summary.csv', index=False)\n",
        "    print(f\"\\nSummary saved to: {output_dir / 'preprocessing_summary.csv'}\")\n",
        "    \n",
        "else:\n",
        "    print(\"No documents were processed.\")\n",
        "\n",
        "print(f\"\\nOutput directory structure:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"pre_proc_op/\")\n",
        "for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "    year_folder = year_folders[year]\n",
        "    file_count = len(list(year_folder.glob(\"*.txt\")))\n",
        "    print(f\"├── {year}/ ({file_count} files)\")\n",
        "    if file_count > 0:\n",
        "        # Show first few files as examples\n",
        "        files = list(year_folder.glob(\"*.txt\"))[:3]\n",
        "        for file in files:\n",
        "            print(f\"│   ├── {file.name}\")\n",
        "        if file_count > 3:\n",
        "            print(f\"│   └── ... and {file_count - 3} more files\")\n",
        "    else:\n",
        "        print(f\"│   └── (no files)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "PREPROCESSING SUMMARY\n",
            "============================================================\n",
            "Total documents processed: 82\n",
            "Total original characters: 137,437\n",
            "Total preprocessed characters: 127,399\n",
            "Overall reduction: 7.1%\n",
            "\n",
            "Preprocessing results by year:\n",
            "--------------------------------------------------\n",
            "      Documents  Original_Chars  Preprocessed_Chars  Avg_Reduction_%\n",
            "year                                                                \n",
            "2020         11           17830               16581              7.1\n",
            "2021         16           28277               26159              6.9\n",
            "2022         15           22467               20923              6.8\n",
            "2023         23           37206               34475              7.1\n",
            "2024         17           31657               29261              7.5\n",
            "\n",
            "Sample preprocessing results:\n",
            "--------------------------------------------------\n",
            "Sample file: 2020 Austrian Grand Prix - Decision - Car 44 - alleged failure to slow for yellow flags.txt\n",
            "Preprocessed file: no_articles_2020 Austrian Grand Prix - Decision - Car 44 - alleged failure to slow for yellow flags.txt\n",
            "Original length: 1438 chars\n",
            "Preprocessed length: 1350 chars\n",
            "Reduction: 6.1%\n",
            "\n",
            "Summary saved to: pre_proc_op\\preprocessing_summary.csv\n",
            "\n",
            "Output directory structure:\n",
            "------------------------------\n",
            "pre_proc_op/\n",
            "├── 2020/ (11 files)\n",
            "│   ├── no_articles_2020 Austrian Grand Prix - Decision - Car 44 - alleged failure to slow for yellow flags.txt\n",
            "│   ├── no_articles_2020 Austrian Grand Prix - Decision - review of decision (document 33).txt\n",
            "│   ├── no_articles_2020 Austrian Grand Prix - Offence - Car 44 - Failure to slow for yellow flags (post review).txt\n",
            "│   └── ... and 8 more files\n",
            "├── 2021/ (16 files)\n",
            "│   ├── no_articles_2021 Austrian Grand Prix - Decision - Car 77 - Alleged driving unnecessarily slowly .txt\n",
            "│   ├── no_articles_2021 Brazilian Grand Prix - Offence - Car 44 - DRS.txt\n",
            "│   ├── no_articles_2021 Brazilian Grand Prix - Offence - Car 44 - PU element.txt\n",
            "│   └── ... and 13 more files\n",
            "├── 2022/ (15 files)\n",
            "│   ├── no_articles_2022 Abu Dhabi Grand Prix - Decision - Car 44 - Red Flag_0.txt\n",
            "│   ├── no_articles_2022 Abu Dhabi Grand Prix - Offence - Car 44 - Pit lane speeding.txt\n",
            "│   ├── no_articles_2022 Abu Dhabi Grand Prix - Offence - Car 63 - Unsafe release.txt\n",
            "│   └── ... and 12 more files\n",
            "├── 2023/ (23 files)\n",
            "│   ├── no_articles_2023 Abu Dhabi Grand Prix - Infringement - Mercedes - Team Principal (Updated).txt\n",
            "│   ├── no_articles_2023 Australian Grand Prix - Decision - Mercedes - Inaccurate Self Scrutineering Form.txt\n",
            "│   ├── no_articles_2023 Austrian Grand Prix - Infringement - Car 44 - Leaving the track multiple times.txt\n",
            "│   └── ... and 20 more files\n",
            "├── 2024/ (17 files)\n",
            "│   ├── no_articles_2024 Austrian Grand Prix - Infringement - Car 44 - Crossing the line at Pit Entry.txt\n",
            "│   ├── no_articles_2024 Austrian Grand Prix - Infringement - Car 44 - Unsafe release.txt\n",
            "│   ├── no_articles_2024 Azerbaijan Grand Prix - Infringement - Car 44 - Changes made during Parc Ferme.txt\n",
            "│   └── ... and 14 more files\n"
          ]
        }
      ],
      "source": [
        "# Summary and analysis of preprocessing results\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PREPROCESSING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if all_processed_docs:\n",
        "    # Create DataFrame for analysis\n",
        "    df_processed = pd.DataFrame(all_processed_docs)\n",
        "    \n",
        "    print(f\"Total documents processed: {len(all_processed_docs)}\")\n",
        "    print(f\"Total original characters: {df_processed['original_length'].sum():,}\")\n",
        "    print(f\"Total preprocessed characters: {df_processed['preprocessed_length'].sum():,}\")\n",
        "    print(f\"Overall reduction: {df_processed['reduction_percent'].mean():.1f}%\")\n",
        "    \n",
        "    print(f\"\\nPreprocessing results by year:\")\n",
        "    print(\"-\" * 50)\n",
        "    year_summary = df_processed.groupby('year').agg({\n",
        "        'original_file': 'count',\n",
        "        'original_length': 'sum',\n",
        "        'preprocessed_length': 'sum',\n",
        "        'reduction_percent': 'mean'\n",
        "    }).round(1)\n",
        "    \n",
        "    year_summary.columns = ['Documents', 'Original_Chars', 'Preprocessed_Chars', 'Avg_Reduction_%']\n",
        "    print(year_summary)\n",
        "    \n",
        "    # Show sample of preprocessing\n",
        "    print(f\"\\nSample preprocessing results:\")\n",
        "    print(\"-\" * 50)\n",
        "    sample_doc = all_processed_docs[0]\n",
        "    print(f\"Sample file: {sample_doc['original_file']}\")\n",
        "    print(f\"Preprocessed file: {sample_doc['preprocessed_file']}\")\n",
        "    print(f\"Original length: {sample_doc['original_length']} chars\")\n",
        "    print(f\"Preprocessed length: {sample_doc['preprocessed_length']} chars\")\n",
        "    print(f\"Reduction: {sample_doc['reduction_percent']:.1f}%\")\n",
        "    \n",
        "    # Save summary\n",
        "    df_processed.to_csv(output_dir / 'preprocessing_summary.csv', index=False)\n",
        "    print(f\"\\nSummary saved to: {output_dir / 'preprocessing_summary.csv'}\")\n",
        "    \n",
        "else:\n",
        "    print(\"No documents were processed.\")\n",
        "\n",
        "print(f\"\\nOutput directory structure:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"pre_proc_op/\")\n",
        "for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "    year_folder = year_folders[year]\n",
        "    file_count = len(list(year_folder.glob(\"*.txt\")))\n",
        "    print(f\"├── {year}/ ({file_count} files)\")\n",
        "    if file_count > 0:\n",
        "        # Show first few files as examples\n",
        "        files = list(year_folder.glob(\"*.txt\"))[:3]\n",
        "        for file in files:\n",
        "            print(f\"│   ├── {file.name}\")\n",
        "        if file_count > 3:\n",
        "            print(f\"│   └── ... and {file_count - 3} more files\")\n",
        "    else:\n",
        "        print(f\"│   └── (no files)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Header Removal - Remove Everything Before \"No / Driver\"\n",
        "\n",
        "This step removes all header information from FIA documents by finding the \"No / Driver\" keyword and removing everything before it. This eliminates:\n",
        "- From/To information\n",
        "- Document numbers\n",
        "- Dates and times\n",
        "- Event headers\n",
        "- Steward information\n",
        "\n",
        "The processed files are saved with the \"no_header_\" prefix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Header removal function\n",
        "\n",
        "def remove_headers_simple(text):\n",
        "    \"\"\"\n",
        "    Remove everything before \"No / Driver\" keyword\n",
        "    If \"No / Driver\" not found, remove header pattern up to Grand Prix date\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    \n",
        "    # First try: Look for \"No / Driver\" pattern (case insensitive)\n",
        "    pattern1 = r'no\\s*/\\s*driver'\n",
        "    match1 = re.search(pattern1, text, re.IGNORECASE)\n",
        "    \n",
        "    if match1:\n",
        "        # Return everything from \"No / Driver\" onwards\n",
        "        return text[match1.start():]\n",
        "    \n",
        "    # Second try: Remove header pattern up to Grand Prix date\n",
        "    # Pattern: \"From Stewards To Team Manager, Mercedes-AMG Petronas F1 TeamDocument XX Date XX Month XXXX Time XX:XX XXXX GRAND PRIX X - X Month XXXX\"\n",
        "    pattern2 = r'from\\s+stewards.*?to\\s+team\\s+manager.*?mercedes.*?document\\s+\\d+.*?date\\s+\\d+.*?time\\s+\\d+:\\d+.*?grand\\s+prix.*?\\d+\\s*-\\s*\\d+.*?\\d{4}'\n",
        "    match2 = re.search(pattern2, text, re.IGNORECASE | re.DOTALL)\n",
        "    \n",
        "    if match2:\n",
        "        # Return everything after the header pattern\n",
        "        return text[match2.end():]\n",
        "    \n",
        "    # Third try: More flexible pattern for different header formats\n",
        "    # Look for \"From\" followed by \"To\" and \"Document\" and \"Date\" patterns\n",
        "    pattern3 = r'from\\s+.*?to\\s+.*?document\\s+\\d+.*?date\\s+\\d+.*?grand\\s+prix.*?\\d{4}'\n",
        "    match3 = re.search(pattern3, text, re.IGNORECASE | re.DOTALL)\n",
        "    \n",
        "    if match3:\n",
        "        # Return everything after the header pattern\n",
        "        return text[match3.end():]\n",
        "    \n",
        "    # If no patterns found, return original text\n",
        "    return text\n",
        "\n",
        "def preprocess_text_with_header_removal(text):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline with header removal\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    \n",
        "    # First remove headers\n",
        "    text = remove_headers_simple(text)\n",
        "    \n",
        "    # Then apply other preprocessing\n",
        "    text = basic_clean(text)\n",
        "    text = remove_articles(text)\n",
        "    \n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "REMOVING HEADERS AND CREATING NO_HEADER_ FILES\n",
            "============================================================\n",
            "\n",
            "Processing 11 files in 2020/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2020:   0%|          | 0/11 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2020: 100%|██████████| 11/11 [00:00<00:00, 266.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 16 files in 2021/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2021: 100%|██████████| 16/16 [00:00<00:00, 383.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 15 files in 2022/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2022: 100%|██████████| 15/15 [00:00<00:00, 382.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 23 files in 2023/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2023: 100%|██████████| 23/23 [00:00<00:00, 432.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 17 files in 2024/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2024: 100%|██████████| 17/17 [00:00<00:00, 364.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total no_header_ files created: 82\n",
            "\n",
            "No_header_ files summary:\n",
            "----------------------------------------\n",
            "2020: 11 no_header_ files\n",
            "2021: 16 no_header_ files\n",
            "2022: 15 no_header_ files\n",
            "2023: 23 no_header_ files\n",
            "2024: 17 no_header_ files\n",
            "\n",
            "Final output directory structure:\n",
            "------------------------------\n",
            "pre_proc_op/\n",
            "├── 2020/ (11 no_articles_, 11 no_header_)\n",
            "│   ├── no_header_2020 Austrian Grand Prix - Decision - Car 44 - alleged failure to slow for yellow flags.txt\n",
            "│   ├── no_header_2020 Austrian Grand Prix - Decision - review of decision (document 33).txt\n",
            "│   └── ... and 9 more no_header_ files\n",
            "├── 2021/ (16 no_articles_, 16 no_header_)\n",
            "│   ├── no_header_2021 Austrian Grand Prix - Decision - Car 77 - Alleged driving unnecessarily slowly .txt\n",
            "│   ├── no_header_2021 Brazilian Grand Prix - Offence - Car 44 - DRS.txt\n",
            "│   └── ... and 14 more no_header_ files\n",
            "├── 2022/ (15 no_articles_, 15 no_header_)\n",
            "│   ├── no_header_2022 Abu Dhabi Grand Prix - Decision - Car 44 - Red Flag_0.txt\n",
            "│   ├── no_header_2022 Abu Dhabi Grand Prix - Offence - Car 44 - Pit lane speeding.txt\n",
            "│   └── ... and 13 more no_header_ files\n",
            "├── 2023/ (23 no_articles_, 23 no_header_)\n",
            "│   ├── no_header_2023 Abu Dhabi Grand Prix - Infringement - Mercedes - Team Principal (Updated).txt\n",
            "│   ├── no_header_2023 Australian Grand Prix - Decision - Mercedes - Inaccurate Self Scrutineering Form.txt\n",
            "│   └── ... and 21 more no_header_ files\n",
            "├── 2024/ (17 no_articles_, 17 no_header_)\n",
            "│   ├── no_header_2024 Austrian Grand Prix - Infringement - Car 44 - Crossing the line at Pit Entry.txt\n",
            "│   ├── no_header_2024 Austrian Grand Prix - Infringement - Car 44 - Unsafe release.txt\n",
            "│   └── ... and 15 more no_header_ files\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Process documents to remove headers and create \"no_header_\" files\n",
        "\n",
        "def process_documents_no_header():\n",
        "    \"\"\"\n",
        "    Process all no_articles_ documents to remove headers and create no_header_ files\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"REMOVING HEADERS AND CREATING NO_HEADER_ FILES\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    processed_count = 0\n",
        "    \n",
        "    for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "        year_folder = year_folders[year]\n",
        "        \n",
        "        # Get all no_articles_ files in this year folder\n",
        "        no_articles_files = list(year_folder.glob(\"no_articles_*.txt\"))\n",
        "        \n",
        "        if not no_articles_files:\n",
        "            print(f\"\\nNo no_articles_ files found in {year}/\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nProcessing {len(no_articles_files)} files in {year}/...\")\n",
        "        \n",
        "        for file_path in tqdm(no_articles_files, desc=f\"Processing {year}\"):\n",
        "            try:\n",
        "                # Read the no_articles_ file\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    content = f.read()\n",
        "                \n",
        "                # Process the content to remove headers\n",
        "                processed_content = preprocess_text_with_header_removal(content)\n",
        "                \n",
        "                # Create output filename with \"no_header_\" prefix\n",
        "                original_filename = file_path.name.replace(\"no_articles_\", \"\")\n",
        "                output_filename = f\"no_header_{original_filename}\"\n",
        "                output_path = year_folder / output_filename\n",
        "                \n",
        "                # Save the processed content\n",
        "                with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write(processed_content)\n",
        "                \n",
        "                processed_count += 1\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_path.name}: {e}\")\n",
        "    \n",
        "    print(f\"\\nTotal no_header_ files created: {processed_count}\")\n",
        "    return processed_count\n",
        "\n",
        "# Process all documents\n",
        "header_processed_count = process_documents_no_header()\n",
        "\n",
        "# Show summary of no_header_ files\n",
        "print(f\"\\nNo_header_ files summary:\")\n",
        "print(\"-\" * 40)\n",
        "for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "    year_folder = year_folders[year]\n",
        "    no_header_files = list(year_folder.glob(\"no_header_*.txt\"))\n",
        "    print(f\"{year}: {len(no_header_files)} no_header_ files\")\n",
        "\n",
        "print(f\"\\nFinal output directory structure:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"pre_proc_op/\")\n",
        "for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "    year_folder = year_folders[year]\n",
        "    no_articles_count = len(list(year_folder.glob(\"no_articles_*.txt\")))\n",
        "    no_header_count = len(list(year_folder.glob(\"no_header_*.txt\")))\n",
        "    print(f\"├── {year}/ ({no_articles_count} no_articles_, {no_header_count} no_header_)\")\n",
        "    \n",
        "    if no_header_count > 0:\n",
        "        # Show first few no_header_ files as examples\n",
        "        files = list(year_folder.glob(\"no_header_*.txt\"))[:2]\n",
        "        for file in files:\n",
        "            print(f\"│   ├── {file.name}\")\n",
        "        if no_header_count > 2:\n",
        "            print(f\"│   └── ... and {no_header_count - 2} more no_header_ files\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Competitor and Time Removal\n",
        "\n",
        "This step removes the competitor and time information from FIA documents. It removes patterns like:\n",
        "- \"Competitor Mercedes-AMG Petronas F1 Team Time 15:59\"\n",
        "- \"Competitor [Team Name] Time [HH:MM]\"\n",
        "\n",
        "The pattern starts with \"Competitor\" and ends with a time in 24-hour format (HH:MM).\n",
        "\n",
        "The processed files are saved with the \"no_comp_time_\" prefix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Competitor and time removal function\n",
        "\n",
        "def remove_competitor_time(text):\n",
        "    \"\"\"\n",
        "    Remove competitor and time information from FIA documents\n",
        "    Pattern: \"Competitor [Team Name] Time [HH:MM]\"\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    \n",
        "    # Pattern to match \"Competitor\" followed by team name and ending with time in HH:MM format\n",
        "    # This will match patterns like:\n",
        "    # \"Competitor Mercedes-AMG Petronas F1 Team Time 15:59\"\n",
        "    # \"Competitor [Any Team Name] Time [HH:MM]\"\n",
        "    pattern = r'competitor\\s+.*?time\\s+\\d{1,2}:\\d{2}'\n",
        "    \n",
        "    # Remove the pattern (case insensitive)\n",
        "    cleaned_text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
        "    \n",
        "    # Clean up any extra whitespace\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
        "    cleaned_text = cleaned_text.strip()\n",
        "    \n",
        "    return cleaned_text\n",
        "\n",
        "def preprocess_text_with_competitor_time_removal(text):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline with competitor and time removal\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    \n",
        "    # Remove competitor and time information\n",
        "    text = remove_competitor_time(text)\n",
        "    \n",
        "    # Apply other preprocessing\n",
        "    text = basic_clean(text)\n",
        "    text = remove_articles(text)\n",
        "    \n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "REMOVING COMPETITOR AND TIME INFO AND CREATING NO_COMP_TIME_ FILES\n",
            "============================================================\n",
            "\n",
            "Processing 11 files in 2020/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2020: 100%|██████████| 11/11 [00:00<00:00, 266.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 16 files in 2021/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2021: 100%|██████████| 16/16 [00:00<00:00, 306.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 15 files in 2022/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2022: 100%|██████████| 15/15 [00:00<00:00, 359.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 23 files in 2023/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2023: 100%|██████████| 23/23 [00:00<00:00, 386.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 17 files in 2024/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2024: 100%|██████████| 17/17 [00:00<00:00, 306.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total no_comp_time_ files created: 82\n",
            "\n",
            "No_comp_time_ files summary:\n",
            "----------------------------------------\n",
            "2020: 11 no_comp_time_ files\n",
            "2021: 16 no_comp_time_ files\n",
            "2022: 15 no_comp_time_ files\n",
            "2023: 23 no_comp_time_ files\n",
            "2024: 17 no_comp_time_ files\n",
            "\n",
            "Final output directory structure:\n",
            "------------------------------\n",
            "pre_proc_op/\n",
            "├── 2020/ (11 no_articles_, 11 no_header_, 11 no_comp_time_)\n",
            "│   ├── no_comp_time_2020 Austrian Grand Prix - Decision - Car 44 - alleged failure to slow for yellow flags.txt\n",
            "│   ├── no_comp_time_2020 Austrian Grand Prix - Decision - review of decision (document 33).txt\n",
            "│   └── ... and 9 more no_comp_time_ files\n",
            "├── 2021/ (16 no_articles_, 16 no_header_, 16 no_comp_time_)\n",
            "│   ├── no_comp_time_2021 Austrian Grand Prix - Decision - Car 77 - Alleged driving unnecessarily slowly .txt\n",
            "│   ├── no_comp_time_2021 Brazilian Grand Prix - Offence - Car 44 - DRS.txt\n",
            "│   └── ... and 14 more no_comp_time_ files\n",
            "├── 2022/ (15 no_articles_, 15 no_header_, 15 no_comp_time_)\n",
            "│   ├── no_comp_time_2022 Abu Dhabi Grand Prix - Decision - Car 44 - Red Flag_0.txt\n",
            "│   ├── no_comp_time_2022 Abu Dhabi Grand Prix - Offence - Car 44 - Pit lane speeding.txt\n",
            "│   └── ... and 13 more no_comp_time_ files\n",
            "├── 2023/ (23 no_articles_, 23 no_header_, 23 no_comp_time_)\n",
            "│   ├── no_comp_time_2023 Abu Dhabi Grand Prix - Infringement - Mercedes - Team Principal (Updated).txt\n",
            "│   ├── no_comp_time_2023 Australian Grand Prix - Decision - Mercedes - Inaccurate Self Scrutineering Form.txt\n",
            "│   └── ... and 21 more no_comp_time_ files\n",
            "├── 2024/ (17 no_articles_, 17 no_header_, 17 no_comp_time_)\n",
            "│   ├── no_comp_time_2024 Austrian Grand Prix - Infringement - Car 44 - Crossing the line at Pit Entry.txt\n",
            "│   ├── no_comp_time_2024 Austrian Grand Prix - Infringement - Car 44 - Unsafe release.txt\n",
            "│   └── ... and 15 more no_comp_time_ files\n"
          ]
        }
      ],
      "source": [
        "# Process documents to remove competitor and time info and create \"no_comp_time_\" files\n",
        "\n",
        "def process_documents_no_competitor_time():\n",
        "    \"\"\"\n",
        "    Process all no_header_ documents to remove competitor and time info and create no_comp_time_ files\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"REMOVING COMPETITOR AND TIME INFO AND CREATING NO_COMP_TIME_ FILES\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    processed_count = 0\n",
        "    \n",
        "    for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "        year_folder = year_folders[year]\n",
        "        \n",
        "        # Get all no_header_ files in this year folder\n",
        "        no_header_files = list(year_folder.glob(\"no_header_*.txt\"))\n",
        "        \n",
        "        if not no_header_files:\n",
        "            print(f\"\\nNo no_header_ files found in {year}/\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nProcessing {len(no_header_files)} files in {year}/...\")\n",
        "        \n",
        "        for file_path in tqdm(no_header_files, desc=f\"Processing {year}\"):\n",
        "            try:\n",
        "                # Read the no_header_ file\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    content = f.read()\n",
        "                \n",
        "                # Process the content to remove competitor and time info\n",
        "                processed_content = preprocess_text_with_competitor_time_removal(content)\n",
        "                \n",
        "                # Create output filename with \"no_comp_time_\" prefix\n",
        "                original_filename = file_path.name.replace(\"no_header_\", \"\")\n",
        "                output_filename = f\"no_comp_time_{original_filename}\"\n",
        "                output_path = year_folder / output_filename\n",
        "                \n",
        "                # Save the processed content\n",
        "                with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write(processed_content)\n",
        "                \n",
        "                processed_count += 1\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_path.name}: {e}\")\n",
        "    \n",
        "    print(f\"\\nTotal no_comp_time_ files created: {processed_count}\")\n",
        "    return processed_count\n",
        "\n",
        "# Process all documents\n",
        "comp_time_processed_count = process_documents_no_competitor_time()\n",
        "\n",
        "# Show summary of no_comp_time_ files\n",
        "print(f\"\\nNo_comp_time_ files summary:\")\n",
        "print(\"-\" * 40)\n",
        "for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "    year_folder = year_folders[year]\n",
        "    no_comp_time_files = list(year_folder.glob(\"no_comp_time_*.txt\"))\n",
        "    print(f\"{year}: {len(no_comp_time_files)} no_comp_time_ files\")\n",
        "\n",
        "print(f\"\\nFinal output directory structure:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"pre_proc_op/\")\n",
        "for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "    year_folder = year_folders[year]\n",
        "    no_articles_count = len(list(year_folder.glob(\"no_articles_*.txt\")))\n",
        "    no_header_count = len(list(year_folder.glob(\"no_header_*.txt\")))\n",
        "    no_comp_time_count = len(list(year_folder.glob(\"no_comp_time_*.txt\")))\n",
        "    print(f\"├── {year}/ ({no_articles_count} no_articles_, {no_header_count} no_header_, {no_comp_time_count} no_comp_time_)\")\n",
        "    \n",
        "    if no_comp_time_count > 0:\n",
        "        # Show first few no_comp_time_ files as examples\n",
        "        files = list(year_folder.glob(\"no_comp_time_*.txt\"))[:2]\n",
        "        for file in files:\n",
        "            print(f\"│   ├── {file.name}\")\n",
        "        if no_comp_time_count > 2:\n",
        "            print(f\"│   └── ... and {no_comp_time_count - 2} more no_comp_time_ files\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Appeal Information Removal\n",
        "\n",
        "This step removes the appeal information and signatures from FIA documents. It removes everything starting from:\n",
        "- \"Competitors are reminded that they have right to appeal...\"\n",
        "\n",
        "This eliminates:\n",
        "- Appeal rights information\n",
        "- Steward signatures\n",
        "- Administrative footers\n",
        "- Legal disclaimers\n",
        "\n",
        "The processed files are saved with the \"no_footer_\" prefix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Appeal information removal function\n",
        "\n",
        "def remove_appeal_info(text):\n",
        "    \"\"\"\n",
        "    Remove appeal information and signatures from FIA documents\n",
        "    Pattern: \"Competitors are reminded that they have right to appeal...\"\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    \n",
        "    # Pattern to match \"Competitors are reminded...\" and everything after it\n",
        "    # This will match patterns like:\n",
        "    # \"Competitors are reminded that they have right to appeal...\"\n",
        "    # \"Competitors are reminded that they have the right to appeal...\"\n",
        "    pattern = r'competitors are reminded.*'\n",
        "    \n",
        "    # Remove the pattern and everything after it (case insensitive)\n",
        "    cleaned_text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.DOTALL)\n",
        "    \n",
        "    # Clean up any extra whitespace\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
        "    cleaned_text = cleaned_text.strip()\n",
        "    \n",
        "    return cleaned_text\n",
        "\n",
        "def preprocess_text_with_appeal_removal(text):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline with appeal information removal\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    \n",
        "    # Remove appeal information\n",
        "    text = remove_appeal_info(text)\n",
        "    \n",
        "    # Apply other preprocessing\n",
        "    text = basic_clean(text)\n",
        "    text = remove_articles(text)\n",
        "    \n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "REMOVING APPEAL INFO AND CREATING NO_FOOTER_ FILES\n",
            "============================================================\n",
            "\n",
            "Processing 11 files in 2020/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2020: 100%|██████████| 11/11 [00:00<00:00, 671.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 16 files in 2021/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2021: 100%|██████████| 16/16 [00:00<00:00, 172.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 15 files in 2022/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2022: 100%|██████████| 15/15 [00:00<00:00, 228.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 23 files in 2023/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2023: 100%|██████████| 23/23 [00:00<00:00, 211.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 17 files in 2024/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2024: 100%|██████████| 17/17 [00:00<00:00, 458.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total no_footer_ files created: 82\n",
            "\n",
            "No_footer_ files summary:\n",
            "----------------------------------------\n",
            "2020: 11 no_footer_ files\n",
            "2021: 16 no_footer_ files\n",
            "2022: 15 no_footer_ files\n",
            "2023: 23 no_footer_ files\n",
            "2024: 17 no_footer_ files\n",
            "\n",
            "Final output directory structure:\n",
            "------------------------------\n",
            "pre_proc_op/\n",
            "├── 2020/ (11 no_articles_, 11 no_header_, 11 no_comp_time_, 11 no_footer_)\n",
            "│   ├── no_footer_2020 Austrian Grand Prix - Decision - Car 44 - alleged failure to slow for yellow flags.txt\n",
            "│   ├── no_footer_2020 Austrian Grand Prix - Decision - review of decision (document 33).txt\n",
            "│   └── ... and 9 more no_footer_ files\n",
            "├── 2021/ (16 no_articles_, 16 no_header_, 16 no_comp_time_, 16 no_footer_)\n",
            "│   ├── no_footer_2021 Austrian Grand Prix - Decision - Car 77 - Alleged driving unnecessarily slowly .txt\n",
            "│   ├── no_footer_2021 Brazilian Grand Prix - Offence - Car 44 - DRS.txt\n",
            "│   └── ... and 14 more no_footer_ files\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "├── 2022/ (15 no_articles_, 15 no_header_, 15 no_comp_time_, 15 no_footer_)\n",
            "│   ├── no_footer_2022 Abu Dhabi Grand Prix - Decision - Car 44 - Red Flag_0.txt\n",
            "│   ├── no_footer_2022 Abu Dhabi Grand Prix - Offence - Car 44 - Pit lane speeding.txt\n",
            "│   └── ... and 13 more no_footer_ files\n",
            "├── 2023/ (23 no_articles_, 23 no_header_, 23 no_comp_time_, 23 no_footer_)\n",
            "│   ├── no_footer_2023 Abu Dhabi Grand Prix - Infringement - Mercedes - Team Principal (Updated).txt\n",
            "│   ├── no_footer_2023 Australian Grand Prix - Decision - Mercedes - Inaccurate Self Scrutineering Form.txt\n",
            "│   └── ... and 21 more no_footer_ files\n",
            "├── 2024/ (17 no_articles_, 17 no_header_, 17 no_comp_time_, 17 no_footer_)\n",
            "│   ├── no_footer_2024 Austrian Grand Prix - Infringement - Car 44 - Crossing the line at Pit Entry.txt\n",
            "│   ├── no_footer_2024 Austrian Grand Prix - Infringement - Car 44 - Unsafe release.txt\n",
            "│   └── ... and 15 more no_footer_ files\n"
          ]
        }
      ],
      "source": [
        "# Process documents to remove appeal info and create \"no_footer_\" files\n",
        "\n",
        "def process_documents_no_footer():\n",
        "    \"\"\"\n",
        "    Process all no_comp_time_ documents to remove appeal info and create no_footer_ files\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"REMOVING APPEAL INFO AND CREATING NO_FOOTER_ FILES\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    processed_count = 0\n",
        "    \n",
        "    for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "        year_folder = year_folders[year]\n",
        "        \n",
        "        # Get all no_comp_time_ files in this year folder\n",
        "        no_comp_time_files = list(year_folder.glob(\"no_comp_time_*.txt\"))\n",
        "        \n",
        "        if not no_comp_time_files:\n",
        "            print(f\"\\nNo no_comp_time_ files found in {year}/\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nProcessing {len(no_comp_time_files)} files in {year}/...\")\n",
        "        \n",
        "        for file_path in tqdm(no_comp_time_files, desc=f\"Processing {year}\"):\n",
        "            try:\n",
        "                # Read the no_comp_time_ file\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    content = f.read()\n",
        "                \n",
        "                # Process the content to remove appeal info\n",
        "                processed_content = preprocess_text_with_appeal_removal(content)\n",
        "                \n",
        "                # Create output filename with \"no_footer_\" prefix\n",
        "                original_filename = file_path.name.replace(\"no_comp_time_\", \"\")\n",
        "                output_filename = f\"no_footer_{original_filename}\"\n",
        "                output_path = year_folder / output_filename\n",
        "                \n",
        "                # Save the processed content\n",
        "                with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write(processed_content)\n",
        "                \n",
        "                processed_count += 1\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_path.name}: {e}\")\n",
        "    \n",
        "    print(f\"\\nTotal no_footer_ files created: {processed_count}\")\n",
        "    return processed_count\n",
        "\n",
        "# Process all documents\n",
        "footer_processed_count = process_documents_no_footer()\n",
        "\n",
        "# Show summary of no_footer_ files\n",
        "print(f\"\\nNo_footer_ files summary:\")\n",
        "print(\"-\" * 40)\n",
        "for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "    year_folder = year_folders[year]\n",
        "    no_footer_files = list(year_folder.glob(\"no_footer_*.txt\"))\n",
        "    print(f\"{year}: {len(no_footer_files)} no_footer_ files\")\n",
        "\n",
        "print(f\"\\nFinal output directory structure:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"pre_proc_op/\")\n",
        "for year in [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
        "    year_folder = year_folders[year]\n",
        "    no_articles_count = len(list(year_folder.glob(\"no_articles_*.txt\")))\n",
        "    no_header_count = len(list(year_folder.glob(\"no_header_*.txt\")))\n",
        "    no_comp_time_count = len(list(year_folder.glob(\"no_comp_time_*.txt\")))\n",
        "    no_footer_count = len(list(year_folder.glob(\"no_footer_*.txt\")))\n",
        "    print(f\"├── {year}/ ({no_articles_count} no_articles_, {no_header_count} no_header_, {no_comp_time_count} no_comp_time_, {no_footer_count} no_footer_)\")\n",
        "    \n",
        "    if no_footer_count > 0:\n",
        "        # Show first few no_footer_ files as examples\n",
        "        files = list(year_folder.glob(\"no_footer_*.txt\"))[:2]\n",
        "        for file in files:\n",
        "            print(f\"│   ├── {file.name}\")\n",
        "        if no_footer_count > 2:\n",
        "            print(f\"│   └── ... and {no_footer_count - 2} more no_footer_ files\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
